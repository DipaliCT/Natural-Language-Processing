{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562a6490",
   "metadata": {},
   "source": [
    "# Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4051abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fec743",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1555d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_table(\"data/train\", header=None, names = ['index', 'word', 'POS_tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76e343e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>POS_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Vinken</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>years</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    word POS_tag\n",
       "0      1  Pierre     NNP\n",
       "1      2  Vinken     NNP\n",
       "2      3       ,       ,\n",
       "3      4      61      CD\n",
       "4      5   years     NNS"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a592b",
   "metadata": {},
   "source": [
    "# Task 1: Vocabulary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c2a0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vocab = {}\n",
    "\n",
    "for i in df_train.index:\n",
    "    word = df_train['word'][i]\n",
    "    if word not in word_vocab:\n",
    "        word_vocab[word] = 1\n",
    "    else:\n",
    "        word_vocab[word] +=1\n",
    "\n",
    "word_vocab = dict(sorted(word_vocab.items(), key = lambda item: item[1], reverse = True))\n",
    "\n",
    "threshold = 4\n",
    "unknown = 0\n",
    "i = 1\n",
    "\n",
    "f = open(\"vocab.txt\", \"w\")\n",
    "\n",
    "for key,val in word_vocab.items():\n",
    "    if val > threshold:\n",
    "        text = key + \"\\\\t\" + str(i) + \"\\\\t\" + str(val) + \"\\n\"\n",
    "        f.write(text)\n",
    "        i += 1\n",
    "    else:\n",
    "        unknown = unknown + val\n",
    "\n",
    "f.close()\n",
    "\n",
    "f = open(\"vocab.txt\", \"r+\")\n",
    "\n",
    "content = f.read()\n",
    "f.seek(0, 0)\n",
    "line = \"<unk>\\\\t0\\\\t\" + str(unknown)\n",
    "f.write(line.rstrip('\\r\\n') + '\\n' + content)\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea61c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43193\n"
     ]
    }
   ],
   "source": [
    "print(len(word_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10120c2e",
   "metadata": {},
   "source": [
    "# Task 2: Model Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ac9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['word'] = df_train['word'].apply(lambda x: '<unk>' if int(word_vocab.get(x, \"0\")) <= threshold else x)\n",
    " \n",
    "POSTag_list = list(df_train['POS_tag'].unique())\n",
    "word_list = list(df_train['word'].unique())\n",
    "\n",
    "POSTag_count = {}\n",
    "\n",
    "for item in POSTag_list:\n",
    "    POSTag_count[item] = 0\n",
    "\n",
    "for i in df_train.index:\n",
    "    POSTag_count[df_train['POS_tag'][i]] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72afafac",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_sum = {}\n",
    "trans_prob = {}\n",
    "\n",
    "for i in range(0, len(df_train)-1):\n",
    "    if (df_train['POS_tag'][i], df_train['POS_tag'][i+1]) in trans_sum:\n",
    "        trans_sum[(df_train['POS_tag'][i], df_train['POS_tag'][i+1])] += 1\n",
    "    else:\n",
    "        trans_sum[(df_train['POS_tag'][i], df_train['POS_tag'][i+1])] = 1\n",
    "\n",
    "for key in trans_sum:\n",
    "    trans_prob[key] = trans_sum[key] / POSTag_count[key[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c9f077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emi_sum = {}\n",
    "emi_prob = {}\n",
    "\n",
    "for i in range(0, len(df_train)):\n",
    "    if (df_train['word'][i], df_train['POS_tag'][i]) in emi_sum:\n",
    "        emi_sum[(df_train['word'][i], df_train['POS_tag'][i])] += 1\n",
    "    else:\n",
    "        emi_sum[(df_train['word'][i], df_train['POS_tag'][i])] = 1\n",
    "\n",
    "for key in emi_sum:\n",
    "    emi_prob[(key[1], key[0])] = emi_sum[key] / POSTag_count[key[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d4123dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stringified_trans_prob = {str(key): value for key, value in trans_prob.items()}\n",
    "stringified_emi_prob = {str(key): value for key, value in emi_prob.items()}\n",
    "\n",
    "with open(\"hmm.json\", \"w\") as outfile:\n",
    "    json.dump(stringified_trans_prob, outfile)\n",
    "    json.dump(stringified_emi_prob, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c376baa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total non-zero transition parameters:  1378\n",
      "Total transition parameters:  2025\n",
      "Total non-zero emission parameters:  17116\n",
      "Total emission parameters:  525960\n"
     ]
    }
   ],
   "source": [
    "m = n = len(POSTag_list) \n",
    "\n",
    "trans_prob_matrix = [[0 for j in range(n)] for i in range(m)]\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        trans_prob_matrix[i][j] = trans_prob.get((POSTag_list[i], POSTag_list[j]), 0)\n",
    "        \n",
    "print(\"Total non-zero transition parameters: \", len(trans_prob))\n",
    "print(\"Total transition parameters: \", m*n)\n",
    "        \n",
    "n = len(word_list)\n",
    "\n",
    "emi_prob_matrix = [[0 for j in range(n)] for i in range(m)]\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        emi_prob_matrix[i][j] = emi_prob.get((POSTag_list[i], word_list[j]), 0)\n",
    "        \n",
    "\n",
    "print(\"Total non-zero emission parameters: \", len(emi_prob))\n",
    "print(\"Total emission parameters: \", m*n)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202dd711",
   "metadata": {},
   "source": [
    "# Task 3: Greedy Decoding with HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d662831",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTag_prob = [0] * len(POSTag_count)\n",
    "\n",
    "i = 0\n",
    "for key,val in POSTag_count.items():  \n",
    "    POSTag_prob[i] = val / len(df_train)\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06390e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_table(\"data/dev\", header=None, names = ['index', 'word', 'POS_tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "605c23b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_algo(df):\n",
    "\n",
    "    tags_greedy = [] \n",
    "    first_word = True\n",
    "    k = 0\n",
    "\n",
    "    for i in df.index:\n",
    "        te_product = []\n",
    "        word = df['word'][i]\n",
    "        if word in word_list:\n",
    "            ind = word_list.index(word)\n",
    "        else:\n",
    "            ind = word_list.index('<unk>')\n",
    "\n",
    "        if first_word: \n",
    "            for j in range(len(POSTag_list)):\n",
    "                te_product.append(POSTag_prob[j] * emi_prob_matrix[j][ind])\n",
    "            first_word = False\n",
    "        else:\n",
    "            for j in range(len(POSTag_list)):\n",
    "                te_product.append(trans_prob_matrix[prev_ind][j] * emi_prob_matrix[j][ind])\n",
    "            if word == \".\":\n",
    "                first_word = True\n",
    "\n",
    "        prev_ind = np.argmax(te_product)\n",
    "        tags_greedy.append([word, POSTag_list[prev_ind]])\n",
    "        \n",
    "    return tags_greedy\n",
    "\n",
    "\n",
    "dev_tags_greedy = greedy_algo(df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2697fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Greedy model: 92.28644283892903\n"
     ]
    }
   ],
   "source": [
    "similarity = 0\n",
    "for i in df_dev.index:\n",
    "    if df_dev['POS_tag'][i] == dev_tags_greedy[i][1]:\n",
    "        similarity += 1\n",
    "        \n",
    "accuracy = similarity / len(df_dev) * 100   \n",
    "\n",
    "print(\"Accuracy of Greedy model:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad2b452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_table(\"data/test\", header=None, names = ['index', 'word', 'POS_tag'])\n",
    "\n",
    "test_tags_greedy = greedy_algo(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b782a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"greedy.out\", \"w\")\n",
    "\n",
    "index = 1\n",
    "for i in df_test.index:\n",
    "    \n",
    "    if i != 0:\n",
    "        if df_test['index'][i] == 1:\n",
    "            index = 1\n",
    "            text = \" \\n\"\n",
    "            f.write(text)\n",
    "        else :\n",
    "            index += 1\n",
    "    \n",
    "    text = str(index) + \"\\t\" + str(test_tags_greedy[i][0]) + \"\\t\" + str(test_tags_greedy[i][1]) + \"\\n\"\n",
    "    f.write(text)       \n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d3d3b",
   "metadata": {},
   "source": [
    "# Task 4: Viterbi Decoding withHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a53f0b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def viterbi_algo(df):\n",
    "\n",
    "    probs = []\n",
    "    current_tags = []\n",
    "    previous_tags = []\n",
    "    \n",
    "    prev_sent_len = 0\n",
    "    tags_viterbi = []\n",
    "\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "\n",
    "    for i in df.index:\n",
    "        if(df['word'][i] == \".\"):\n",
    "            sentence.append(\".\")\n",
    "            sentences.append(sentence)\n",
    "            sentence = []\n",
    "        else:\n",
    "            sentence.append(df['word'][i])\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "\n",
    "        sentence_tags = []\n",
    "        first_word = True\n",
    "        te_products = {}\n",
    "\n",
    "        for j in range(len(sentences[i])):\n",
    "\n",
    "            te_product = []\n",
    "            te_products = {}\n",
    "\n",
    "            max_prob = 0\n",
    "            max_ind = 0\n",
    "\n",
    "            word = sentences[i][j]\n",
    "\n",
    "            if word in word_list:\n",
    "                ind = word_list.index(word)\n",
    "            else:\n",
    "                ind = word_list.index('<unk>')\n",
    "\n",
    "            if first_word: \n",
    "\n",
    "                prob = [0] * len(POSTag_list)\n",
    "                current_tag = [0] * len(POSTag_list)\n",
    "                previous_tag = [0] * len(POSTag_list)\n",
    "\n",
    "                for k in range(len(POSTag_list)):\n",
    "                    te_product.append(POSTag_prob[k] * emi_prob_matrix[k][ind])\n",
    "\n",
    "                max_prob = np.max(te_product)\n",
    "                max_ind = np.argmax(te_product)\n",
    "\n",
    "                prob[max_ind] = max_prob\n",
    "                current_tag[max_ind] = POSTag_list[max_ind]\n",
    "\n",
    "                first_word = False\n",
    "\n",
    "            else:\n",
    "\n",
    "                for l in range(len(prob)):            \n",
    "                    te_product = []\n",
    "                    if(prob[l] > 0): #selecting all previous probability with values greater than 0 i.e. only changed tags                  \n",
    "\n",
    "                        for k in range(len(POSTag_list)):\n",
    "                            te_product.append(trans_prob_matrix[l][k] * emi_prob_matrix[k][ind] * prob[l])\n",
    "\n",
    "                        te_products[l] = te_product\n",
    "\n",
    "                prob = [0] * len(POSTag_list)\n",
    "                current_tag = [0] * len(POSTag_list)\n",
    "                previous_tag = [0] * len(POSTag_list)\n",
    "\n",
    "                list_of_keys = list(te_products.keys())\n",
    "                list_of_values = list(te_products.values())\n",
    "\n",
    "                max_values = []\n",
    "                max_indices = []\n",
    "\n",
    "                for column_index in range(len(POSTag_list)):\n",
    "                    if(len(list_of_values) > 0):\n",
    "                        max_prob = max([row[column_index] for row in list_of_values])\n",
    "                        max_ind = np.argmax([row[column_index] for row in list_of_values])\n",
    "\n",
    "                    if(max_prob > 0):\n",
    "                        prob[column_index] = max_prob\n",
    "                        current_tag[column_index] = POSTag_list[column_index]               \n",
    "                        previous_tag[column_index] = POSTag_list[list_of_keys[max_ind]] \n",
    "\n",
    "                if word == \".\":\n",
    "                    first_word = True\n",
    "                    current_tag[POSTag_list.index(\".\")] = \".\" #in case probability of one word converges to 0\n",
    "\n",
    "            probs.append(prob)\n",
    "            current_tags.append(current_tag)\n",
    "            previous_tags.append(previous_tag)  \n",
    "\n",
    "\n",
    "        sentence_len = len(sentences[i])\n",
    "        sentence_tags.append(\".\")\n",
    "\n",
    "        for index in range(sentence_len - 1, 0, -1):\n",
    "\n",
    "            if index == sentence_len - 1:\n",
    "                prev_index = current_tags[prev_sent_len + sentence_len - 1].index(\".\")\n",
    "            else: \n",
    "                prev_index = current_tags[prev_sent_len + index].index(prev_tag)\n",
    "\n",
    "            prev_tag = previous_tags[prev_sent_len + index][prev_index]\n",
    "\n",
    "            sentence_tags.append(prev_tag)\n",
    "\n",
    "        prev_sent_len += sentence_len\n",
    "\n",
    "        sentence_tags.reverse()\n",
    "        tags_viterbi.extend(sentence_tags)\n",
    "        \n",
    "    return tags_viterbi\n",
    " \n",
    "\n",
    "dev_tags_viterbi = viterbi_algo(df_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35528936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Viterbi model: 93.53712585756784\n"
     ]
    }
   ],
   "source": [
    "similarity = 0\n",
    "for i in df_dev.index:\n",
    "    if df_dev['POS_tag'][i] == dev_tags_viterbi[i]:\n",
    "        similarity += 1\n",
    "        \n",
    "accuracy = similarity /len(df_dev) * 100   \n",
    "\n",
    "print(\"Accuracy of Viterbi model:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acd388d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tags_viterbi = viterbi_algo(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cedfb228",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"viterbi.out\", \"w\")\n",
    "\n",
    "index = 1\n",
    "for i in df_test.index:\n",
    "    \n",
    "    if i != 0:\n",
    "        if df_test['index'][i] == 1:\n",
    "            index = 1\n",
    "            text = \" \\n\"\n",
    "            f.write(text)\n",
    "        else :\n",
    "            index += 1\n",
    "    \n",
    "    text = str(index) + \"\\t\" + str(df_test['word'][i]) + \"\\t\" + str(test_tags_viterbi[i]) + \"\\n\"\n",
    "    f.write(text)       \n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e16490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
